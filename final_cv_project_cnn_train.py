# -*- coding: utf-8 -*-
"""final_cv_project_cnn_train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s2eUSi_7-3KxwTcGZZKyI0YYl0JtyJn6
"""

import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import Dataset, SubsetRandomSampler,DataLoader
import os
import torch
from PIL import Image
from torch.utils.data import Dataset
# from torch.utils.data import DataLoader, SubsetRandomSampler
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_curve, roc_auc_score
import random

!unzip /content/drive/MyDrive/Inian_sign_language.zip

class IndianSignLanguageDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.labels = sorted(os.listdir(root_dir))
        self.label_to_idx = {label: idx for idx, label in enumerate(self.labels)}
        self.image_paths = []
        for label in self.labels:
            label_dir = os.path.join(root_dir, label)
            for image_path in os.listdir(label_dir):
                self.image_paths.append(os.path.join(label, image_path))

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, index):
        image_path = os.path.join(self.root_dir, self.image_paths[index])
        image = Image.open(image_path).convert('RGB')
        label = self.label_to_idx[image_path.split(os.sep)[-2]]
        if self.transform:
            image = self.transform(image)
        return image, label

# Define the transforms to be applied to the dataset
transform = transforms.Compose(
    [transforms.Resize((128, 128)),
     transforms.RandomHorizontalFlip(p=0.5),
     transforms.RandomRotation(degrees=(-30, 30)),
     transforms.RandomVerticalFlip(p=0.5),
     transforms.RandomAffine(degrees=(-30, 30), translate=(0.1, 0.1), scale=(0.9, 1.1), shear=(-10, 10)),
     transforms.ToTensor(),
     transforms.Normalize((0.5,), (0.5,))])

# Create the dataset
my_dataset = IndianSignLanguageDataset(root_dir="/content/data", transform=transform)


# Shuffle the dataset
shuffled_indices = torch.randperm(len(my_dataset)).tolist()
my_dataset = torch.utils.data.Subset(my_dataset, shuffled_indices)

# # Define the size of the training set
# train_size = int(0.8 * len(my_dataset))
# test_size = len(my_dataset) - train_size

# # Define the indices for the training and testing sets
# train_indices, test_indices = shuffled_indices[:train_size], shuffled_indices[train_size:]
# Define the size of the training, validation, and testing sets
train_size = int(0.7 * len(my_dataset))
val_size = int(0.1 * len(my_dataset))
test_size = len(my_dataset) - train_size - val_size

# Define the indices for the training, validation, and testing sets
train_indices = shuffled_indices[:train_size]
val_indices = shuffled_indices[train_size:train_size + val_size]
test_indices = shuffled_indices[train_size + val_size:]

print(train_indices)
print(test_indices)
print(val_indices)

# Create the data samplers for the training and testing sets
train_sampler = SubsetRandomSampler(train_indices)
test_sampler = SubsetRandomSampler(test_indices)
val_sampler = SubsetRandomSampler(val_indices)

# Create the data loaders for the training and testing sets
train_loader = DataLoader(my_dataset, batch_size=64, sampler=train_sampler)
test_loader = DataLoader(my_dataset, batch_size=64, sampler=test_sampler)
val_loader = DataLoader(my_dataset, batch_size=64, sampler=val_sampler)

# Print the shape of each batch and corresponding labels
for i, (images, labels) in enumerate(train_loader):
    print(f"Batch {i+1} - Image Shape: {images.shape}, Labels: {labels}")
    if i==2:
      break

# Print the shape of each batch and corresponding labels
for i, (images, labels) in enumerate(test_loader):
    print(f"Batch {i+1} - Image Shape: {images.shape}, Labels: {labels}")
    if i==2:
      break

print(len(train_loader))
print(len(test_loader))

import torch.nn.init as init
import torch.nn as nn
import torch.nn.functional as F

class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
         #input shape is [batch=32,channels=3,size = 128*128] and 3 filters
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=3, padding=1) 
        #new shape = [32,3,128,128]
        # self.bn1 = nn.BatchNorm2d(5)
        self.conv2 = nn.Conv2d(in_channels=5, out_channels=5, kernel_size=3, padding=1)
        #new shape = [32,5,128,128]
        self.bn2 = nn.BatchNorm2d(5)
        self.conv3 = nn.Conv2d(in_channels=5, out_channels=6, kernel_size=3, padding=1)
        #new shape = [32,6,64,64]
        # self.bn3 = nn.BatchNorm2d(7)
        self.conv4 = nn.Conv2d(in_channels=6, out_channels=6, kernel_size=3, padding=1)
        #new shape = [32,6,64,64]
        self.bn4 = nn.BatchNorm2d(6)
        self.conv5 = nn.Conv2d(in_channels=6, out_channels=8, kernel_size=3, padding=1)
        #new shape = [32,8,32,32]
        # self.bn5 = nn.BatchNorm2d(9)
        self.conv6 = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3, padding=1)
        #new shape = [32,8,16,16]
        self.bn6 = nn.BatchNorm2d(8)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.fc1 = nn.Linear(in_features=8 * 16 * 16, out_features=64)
        self.fc2 = nn.Linear(in_features=64, out_features=35)
        self.dropout = nn.Dropout(p=0.5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.relu(self.bn2(self.conv2(x)))
        x = self.pool(F.relu(self.conv3(x)))
        x = F.relu(self.bn4(self.conv4(x)))
        x = self.pool(F.relu(self.conv5(x)))
        x = self.pool(F.relu(self.bn6(self.conv6(x))))
        x = x.view(-1, 8 * 16 * 16)
        x = F.relu(self.dropout(self.fc1(x)))
        x = self.fc2(x)
        # x = F.softmax(x, dim=1)  # Apply softmax activation
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, nn.BatchNorm2d):
                init.constant_(m.weight, 1)
                init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                init.constant_(m.bias, 0)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = CNN().to(device)

# Define the loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.00001)

import random
import torch.nn.functional as F

# Set random seed for reproducibility
random_seed = 42
torch.manual_seed(random_seed)
if torch.cuda.is_available():
    torch.cuda.manual_seed(random_seed)

# Define the L1 regularization strength
l1_lambda = 0.001

# Train the model
train_losses = []
val_losses = []
train_total = 0
train_correct = 0
val_total = 0
val_correct = 0

for epoch in range(20):
    # Training steps...
    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        inputs, labels = data[0].to(device), data[1].to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)  # Calculate the loss

        # L1 regularization
        l1_regularization = torch.tensor(0., device=device)
        for param in model.parameters():
            l1_regularization += torch.norm(param, p=1)

        loss += l1_lambda * l1_regularization

        loss.backward()  # Backpropagate the loss
        optimizer.step()  # Optimize the weights
        running_loss += loss.item()
        if i % 100 == 99:
            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))
            train_losses.append(running_loss / 100)
            running_loss = 0.0
            
        # Update total and correct variables for training accuracy
        train_total += labels.size(0)
        _, predicted = torch.max(outputs.data, 1)
        train_correct += (predicted == labels).sum().item()

    # Set the model to evaluation mode
    model.eval()
    with torch.no_grad():
        for data in val_loader:
            images, labels = data[0].to(device), data[1].to(device)
            outputs = model(images)
            # Compute test accuracy
            _, predicted = torch.max(outputs.data, 1)
            val_total += labels.size(0)
            val_correct += (predicted == labels).sum().item()

            # Calculate loss for the batch and update running loss
            loss = criterion(outputs, labels)
            running_loss += loss.item()

    # Compute test accuracy and loss for the epoch
    val_accuracy = 100 * val_correct / val_total
    val_loss = running_loss / len(val_loader)
    val_losses.append(val_loss)

    # Print test accuracy and loss for the epoch
    print('Epoch %d, val Loss: %.3f, val Accuracy: %.3f' % (epoch + 1, val_loss, val_accuracy))

    # Compute and print training accuracy
    train_accuracy = 100 * train_correct / train_total
    print('Epoch %d, Training Accuracy: %.3f' % (epoch + 1, train_accuracy))

    # if test_loss>loss:
    #   break

print(train_losses)

# Initialize a new list to store the loss values for every 5th element
train_losses_5th = []

for i, loss in enumerate(train_losses, 1):
    if i % 4 == 0:
        train_losses_5th.append(loss)

# Print the loss values for every 5th element
print(train_losses_5th)

# from google.colab import drive
# drive.mount('/content/drive')

# Plot training loss vs epoch
plt.plot(train_losses)
plt.xlabel('Epoch')
plt.ylabel('Training Loss')
plt.title('Training Loss after every 100 iteration vs Epoch')
plt.show()

print('Finished Training')

# Plot the training loss and validation loss curve
plt.figure()
plt.plot(range(1, len(train_losses_5th) + 1), train_losses_5th, label='Training Loss')
plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Save the model, optimizer, and training history to a checkpoint file
checkpoint = {'modelfinal1': model.state_dict(),
              'optimizerfinal1': optimizer.state_dict(),
              'train_lossesfinal1': train_losses}
torch.save(checkpoint, 'checkpointfinal2.pth')

# Load the checkpoint file
checkpoint = torch.load('checkpointfinal2.pth')

# # # Create a new model and optimizer
# model = CNN().to(device)
# optimizer = optim.Adam(model.parameters(), lr=0.00001)

# Load the saved model and optimizer states
model.load_state_dict(checkpoint['modelfinal1'])
# optimizer.load_state_dict(checkpoint['optimizerfinal1'])
# Put the model in evaluation mode
# model.eval()

class_names = ['1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']

# Create empty lists to store true labels and predicted labels
true_labels = []
pred_labels = []

# Loop through the test data and make predictions
with torch.no_grad():
    for data in test_loader:
        images, labels = data[0].to(device), data[1].to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        true_labels += labels.tolist()
        pred_labels += predicted.tolist()

# Calculate the confusion matrix
cm = confusion_matrix(true_labels, pred_labels, labels=range(len(class_names)))

# Calculate the overall and classwise accuracy
acc = accuracy_score(true_labels, pred_labels)*100
report = classification_report(true_labels, pred_labels,target_names=class_names)

print(f"Confusion Matrix:\n{cm}")
print(f"\nOverall Accuracy: {acc}")
print(f"\nClassification Report:\n{report}")

import numpy as np

# Save the confusion matrix to a file
np.savetxt('confusion_matrixfinal.txt', cm, fmt='%d')

# Load the file contents and print
with open('confusion_matrixfinal.txt', 'r') as file:
    confusion_matrix_text = file.read()

print('Confusion Matrix:')
print(confusion_matrix_text)

class_names = ['1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']

# Create empty lists to store true labels and predicted labels
true_labels = []
pred_labels = []

# Create empty list to store predicted values and original values side by side
predictions = []

# Loop through the test data and make predictions
with torch.no_grad():
    for data in test_loader:
        images, labels = data[0].to(device), data[1].to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        true_labels += labels.tolist()
        pred_labels += predicted.tolist()
        
        # Append predicted and original values side by side
        for true_label, pred_label in zip(labels.tolist(), predicted.tolist()):
            predictions.append((class_names[true_label], class_names[pred_label]))

# # Calculate the confusion matrix
# cm = confusion_matrix(true_labels, pred_labels, labels=range(len(class_names)))

# Calculate the overall and classwise accuracy
acc = accuracy_score(true_labels, pred_labels) * 100
report = classification_report(true_labels, pred_labels, target_names=class_names)

# print(f"Confusion Matrix:\n{cm}")
# print(f"\nOverall Accuracy: {acc}")
# print(f"\nClassification Report:\n{report}")

# Print predicted values and original values side by side
for true_label, pred_label in predictions:
    print(f"True: {true_label}\tPredicted: {pred_label}")