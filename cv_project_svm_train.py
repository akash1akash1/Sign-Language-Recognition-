# -*- coding: utf-8 -*-
"""cv_project_svm_train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10T7ptMuuW8-nllb2mmwKwgGGbmJuNfJH
"""

# from google.colab import drive
# drive.mount('/content/drive')

import cv2
import numpy as np
# from google.colab.patches import cv2_imshow
import numpy as np
from sklearn.cluster import MiniBatchKMeans

!unzip /content/drive/MyDrive/Inian_sign_language.zip

import os

dataset_path ="/content/data"
# List all the image file paths
image_paths = []
labels = []
for folder in os.listdir(dataset_path):
    folder_path = os.path.join(dataset_path, folder)
    if os.path.isdir(folder_path):
        for filename in os.listdir(folder_path):
            img_path = os.path.join(folder_path, filename)
            image_paths.append(img_path)
            labels.append(folder)

from sklearn.model_selection import train_test_split

# Split the image file paths and labels into train and test sets
train_paths, test_paths, train_labels, test_labels = train_test_split(image_paths, labels, test_size=0.2, random_state=42)

# Print the number of images in each set
print(f"Number of training images: {len(train_paths)}")
print(f"Number of test images: {len(test_paths)}")

# # Select a subset of images from the train and test sets
# train_paths_subset = train_paths[:100]
# train_labels_subset = train_labels[:100]
# test_paths_subset = test_paths[:50]
# test_labels_subset = test_labels[:50]

# print(f"number of trainig images : {len(train_paths_subset)}")
# print(f"number of trainig labels : {len(train_labels_subset)}")
# print(f"number of test images : {len(test_paths_subset)}")
# print(f"number of test labels : {len(test_labels_subset)}")

import numpy as np

# Count the number of occurrences of each label in the training set
unique_labels, counts = np.unique(test_labels, return_counts=True)

# Print the number of occurrences of each label
print("Number of occurrences of each label in the training set:")
for label, count in zip(unique_labels, counts):
    print(f"{label}: {count}")

# Print the classes
print("Classes:")
print(np.unique(labels))

def extract_features(img_path):
    # Read the image
    img = cv2.imread(img_path)

    # Apply skin masking
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    lower_skin = np.array([0, 20, 70], dtype=np.uint8)
    upper_skin = np.array([20, 255, 255], dtype=np.uint8)
    mask = cv2.inRange(hsv, lower_skin, upper_skin)
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
    result = cv2.bitwise_and(img, img, mask=mask)

    # Convert image to grayscale
    gray = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)

    # Create SIFT object and find keypoints and descriptors
    sift = cv2.SIFT_create()
    kp, des = sift.detectAndCompute(gray, None)

    return des

X_train = []
y_train = []

for i, img_path in enumerate(train_paths):
    # Extract features using the function
    des = extract_features(img_path)
    
    # Save the SIFT descriptors and corresponding label
    X_train.append(des)
    y_train.append(train_labels[i])

print(len(X_train))
print(len(y_train))

# Flatten the SIFT feature vectors
X_train_flat = np.concatenate(X_train)

# Create Mini Batch K-Means object
mbk = MiniBatchKMeans(n_clusters=50, random_state=0, batch_size=100)

# Fit the Mini Batch K-Means model to the SIFT features
mbk.fit(X_train_flat)

# Calculate the histogram of visual words for each image
X_train_hist = []
for des in X_train:
    pred = mbk.predict(des)
    hist, _ = np.histogram(pred, bins=range(51))
    X_train_hist.append(hist)

from sklearn import svm

# Train the SVM model
clf = svm.SVC(kernel='linear')
clf.fit(X_train_hist, y_train)

import sklearn
print(sklearn.__version__)

import joblib
# Save the trained models
joblib.dump(mbk, 'mbk_model_final.pkl')

joblib.dump(clf, 'svm_model_final.pkl')

from sklearn.metrics import confusion_matrix, classification_report
from joblib import load

# Load the trained models
mbk = load('mbk_model_final.pkl')
clf = load('svm_model_final.pkl')


X_test = []
y_test = []

for i, img_path in enumerate(test_paths):
    # Extract features using the function
    des = extract_features(img_path)
    
    # Save the SIFT descriptors and corresponding label
    X_test.append(des)
    y_test.append(test_labels[i])

X_test_flat = np.concatenate(X_test)

# Predict visual words for test images
X_test_hist = []
for des in X_test:
    pred = mbk.predict(des)
    hist, _ = np.histogram(pred, bins=range(51))
    X_test_hist.append(hist)

# Perform predictions using the trained SVM model
y_pred = clf.predict(X_test_hist)

class_names = ['1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']

from sklearn.metrics import accuracy_score

# Calculate overall accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Overall Accuracy:", accuracy)

# Calculate confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)

# Calculate classification report
classification_rep = classification_report(y_test, y_pred,target_names=class_names)
print("Classification Report:")
print(classification_rep)

# X_test = []
# y_test = []

# for i, img_path in enumerate(test_paths):
#     # Extract features using the function
#     des = extract_features(img_path)
    
#     # Save the SIFT descriptors and corresponding label
#     X_test.append(des)
#     y_test.append(test_labels[i])

# # Flatten the SIFT feature vectors
# X_test_flat = np.concatenate(X_test)

# # Calculate the histogram of visual words for each image
# X_test_hist = []
# for des in X_test:
#     pred = mbk.predict(des)
#     hist, _ = np.histogram(pred, bins=range(51))
#     X_test_hist.append(hist)

# # Use the trained SVM classifier to predict the labels for the test set
# y_pred = clf.predict(X_test_hist)

# # # Print the predicted labels and the true labels for the test set
# # print("Predicted labels:", y_pred)
# # print("True labels:", y_test)

# # Stack the true labels and predicted labels horizontally
# labels = np.column_stack((np.array(y_test), y_pred))

# # Print the labels
# print(labels)

# import cv2
# import joblib
# import numpy as np
#
# # Load the trained models
# mbk_model = joblib.load('mbk_model_final.pkl')
# svm_model = joblib.load('svm_model_final.pkl')
#
# cam = cv2.VideoCapture(0)
# while True:
#     ret, frame = cam.read()
#     if not ret:
#         print("Failed to read frame from camera")
#         break
#     frame = cv2.flip(frame, 1)
#     cv2.rectangle(frame, (319, 9), (620 + 1, 309), (0, 255, 0), 1)
#     roi = frame[10:300, 320:620]
#
#     # cv2.imshow("Frame", frame)
#     # des = extract_features(roi)
#     hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
#     lower_skin = np.array([0, 20, 70], dtype=np.uint8)
#     upper_skin = np.array([20, 255, 255], dtype=np.uint8)
#     mask = cv2.inRange(hsv, lower_skin, upper_skin)
#     kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))
#     mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
#     result = cv2.bitwise_and(roi, roi, mask=mask)
#
#     # Convert image to grayscale
#     gray = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)
#
#     # Create SIFT object and find keypoints and descriptors
#     sift = cv2.SIFT_create()
#     kp, des = sift.detectAndCompute(gray, None)
#     # pred = mbk.predict(des)
#     # hist, _ = np.histogram(pred, bins=range(51))
#     # # y_pred = clf.predict(hist)
#     # y_pred = clf.predict(hist.reshape(1, -1))
#     if des is not None:
#         pred = mbk_model.predict(des)
#         hist, _ = np.histogram(pred, bins=range(51))
#         y_pred = svm_model.predict(hist.reshape(1, -1))
#         cv2.putText(frame, str(y_pred[0]), (10, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 1)
#
#
#     # print(alpha_dict[np.argmax(pred)])
#     # cv2.putText(frame,y_pred, (10, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 1)
#     cv2.putText(frame, str(y_pred[0]), (10, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 1)
#     cv2.imshow("Frame", frame)
#     k = cv2.waitKey(100) & 0xFF
#     if k == 27:
#         break
#
# cam.release()
# cv2.destroyAllWindows()